(window.webpackJsonp=window.webpackJsonp||[]).push([[92],{579:function(e,a,t){"use strict";t.r(a);var r=t(6),o=Object(r.a)({},(function(){var e=this,a=e.$createElement,t=e._self._c||a;return t("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[t("h2",{attrs:{id:"hbase-mapreduce处理分布式数据"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#hbase-mapreduce处理分布式数据"}},[e._v("#")]),e._v(" HBase(MapReduce处理分布式数据)")]),e._v(" "),t("p",[e._v("MapReduce 是 Hadoop 框架的重要组成部分，是在可扩展的方式下处理超过 TB 级数据的分布式处理的组件。它遵循分而治之的原则，通过将数据拆分到分布式文件系统中的不同机器上， 让服务器能够尽快直接访问和处理数据，最终合并全局结果。")]),e._v(" "),t("p",[e._v("以下图所示网站点击率排行为例，简单介绍 MapReduce 处理数据的过程。")]),e._v(" "),t("p",[t("img",{attrs:{src:"http://c.biancheng.net/uploads/allimg/191115/6-191115152106227.gif",alt:"RUNOOB 图标"}})]),e._v(" "),t("p",[e._v("HBase 中 MapRecude 包\nMapReduce 可用于完成批量数据的分布式处理，而 HBase 中表格的数据是非常庞大的，通常是 GB 或 TB 级，将 MapReduce 和 HBase 结合，能快速完成批量数据的处理。")]),e._v(" "),t("p",[e._v("在应用过程中，HBase 可以作为数据源，即将表中的数据作为 MapReduce 的输入；同时，HBase 可以在 MapReduce 作业结束时接收数据，甚至在 MapReduce 任务过程中使用 HBase 来共享资源。")]),e._v(" "),t("p",[e._v("HBase 支持使用 org.apache.hadoop.hbase.mapieduce 包中的方法来实现 MapReduce 作业，完成 HBase 表中数据的功能如下表所示。")]),e._v(" "),t("p",[e._v("hbase.mapreduce 包")]),e._v(" "),t("table",[t("thead",[t("tr",[t("th",[e._v("类名")]),e._v(" "),t("th",[e._v("描述")])])]),e._v(" "),t("tbody",[t("tr",[t("td",[e._v("CellCounter")]),e._v(" "),t("td",[e._v("利用 MapReduce 计算表中单元格的个数")])]),e._v(" "),t("tr",[t("td",[e._v("Export")]),e._v(" "),t("td",[e._v("将 HBase 中的表导出序列化文件，存储在 HDFS 中")])]),e._v(" "),t("tr",[t("td",[e._v("GroupingTableMapper")]),e._v(" "),t("td",[e._v("从输入记录中抽取列进行组合")])]),e._v(" "),t("tr",[t("td",[e._v("HFileOutputFormat2")]),e._v(" "),t("td",[e._v("写入 HFile 文件")])]),e._v(" "),t("tr",[t("td",[e._v("HRegionPartitioner:KEY,VALUE")]),e._v(" "),t("td",[e._v("将输出的 key 分到指定的 key 分组中。key 是根据已存在的 Region 进行分组的，所以每个Reduce拥有一个单独的 Region")])]),e._v(" "),t("tr",[t("td",[e._v("Import")]),e._v(" "),t("td",[e._v("导入 HDFS 中的序列化文件这些文件是由 Export 导出的")])]),e._v(" "),t("tr",[t("td",[e._v("ImportTsv")]),e._v(" "),t("td",[e._v("导入 TSV 文件的数据")])]),e._v(" "),t("tr",[t("td",[e._v("KeyValueSortReducer")]),e._v(" "),t("td",[e._v("产生排序的键值")])]),e._v(" "),t("tr",[t("td",[e._v("LoadIncrementalHFiles")]),e._v(" "),t("td",[e._v("将 HFileOutputFormat2 的输出导入 HBase 表")])]),e._v(" "),t("tr",[t("td",[e._v("MultiTableInputFormat")]),e._v(" "),t("td",[e._v("将表格数据转换为 MapReduce 格式")])]),e._v(" "),t("tr",[t("td",[e._v("MultiTableOutputFormat")]),e._v(" "),t("td",[e._v("将 Hadoop 的输出写到一个或多个 HBase 表中")])]),e._v(" "),t("tr",[t("td",[e._v("TableInputFormat")]),e._v(" "),t("td",[e._v("将 HBase 表的数据转化为 MapReduce 格式")])]),e._v(" "),t("tr",[t("td",[e._v("TableOutputFormat:KEY:")]),e._v(" "),t("td",[e._v("转化 MapReduce 的输出，写入 HBase 中")])]),e._v(" "),t("tr",[t("td",[e._v("TableSplit")]),e._v(" "),t("td",[e._v("对表进行拆分")])]),e._v(" "),t("tr",[t("td",[e._v("WALInputFormat")]),e._v(" "),t("td",[e._v("作为输入格式用于 WAL")])])])]),e._v(" "),t("p",[e._v("HBase 还提供了 HBase MapReduce 作业中用到的输入/输出格式化等其他辅助工具，这些都是利用 MapReduce 框架完成的。")]),e._v(" "),t("p",[e._v("读者若要了解更多功能请参考 HBase MapReduce API 官网。\n执行 HBase MapReduce 任务\nHBase 可以通过执行 hbase/lib 中的 hbase-server-1.2.6.jar 来完成一些简单的 MapReduce 操作。")]),e._v(" "),t("p",[e._v("下面通过 hbase/bin/hbase mapredcp 命令来查看执行 MapReduce 会用到的 jar 文件。")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",[t("code",[e._v("[root@localhost bin]# ./hbase mapredcp/usr/local/hbase/lib/zookeeper-3.4.6.jar:/usr/local/hbase/lib/hbase-client-1.2.6.j ar:/usr/local/hbase/lib/netty-all-4.0.23.Final.jar:/usr/local/hbase/lib/metrics-core-2 .2.0.jar:/usr/local/hbase/lib/protobuf-java—2.5.0.jar:/usr/local/hbase/lib/guava-12.0. 1.jar:/usr/local/hbase/lib/hbase-protocol-1.2.6.jar:/usr/local/hbase/lib/hbase-prefix-tree-1.2.6.jar:/usr/local/hbase/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hbase/ lib/hbase-common-1.2.6.jar:/usr/local/hbase/lib/hbase-hadoop-compat-1.2.6.jar:/usr/loc al/hbase/lib/hbase-server-1.2.6.jar\n")])])]),t("p",[e._v("在执行这些任务之前，需要将这些库绑定到 Hadoop 框架中，确保这些库在任务执行之前已 经可用，通过修改 hadoop/etc/hadoop-env.sh 文件来配置库文件。")]),e._v(" "),t("p",[e._v("在 hadoop-env.sh 中加入以下两行代码：\n#hbase的安装路径\nexport HBASE_HOME=/usr/local/hbase\n#加载hbase/lib下的所有库\nexport HADOOP_CLASSPATH= $HBASE_HOME/lib/*:classpath")]),e._v(" "),t("p",[e._v("完成以上配置后，重新启动 Hadoop 服务，然后在 hadoop 的 bin 目录中执行以下命令:")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",[t("code",[e._v("[root@localhost bin]# hadoop jar ../../hbase/lib/hbase-server-1.2.6.jar\nAn example program must be given as the first argument.\nValid program names are:\n    CellCounter: Count cells in HBase table.\n    WALPlayer: Replay WAL files.\n    completebulkload: Complete a bulk data load.\n    copytable: Export a table from local cluster to peer cluster.\n    export: Write table data to HDFS.\n    exportsnapshot: Export the specific snapshot to a given FileSystem.\n    import: Import data written by Export.\n    importtsv: Import data in TSV format.\n    rowcounter: Count rows in HBase table.\n    verifyrep: Compare the data from tables in two different clusters. WARNING: It doesn ' t work for incrementColumnValues'd cells since the timestamp is changed after being appended to the log.\n")])])]),t("p",[e._v("hbase-server-1.2.6.jar 包提供 CellCounter、export、 import、rowcounter 等类，用户可以直接使用，下图所示为使用 rowcounter 类来统计表中的行数。")]),e._v(" "),t("p",[t("img",{attrs:{src:"http://c.biancheng.net/uploads/allimg/191115/6-191115154R1200.gif",alt:"RUNOOB 图标"}})])])}),[],!1,null,null,null);a.default=o.exports}}]);