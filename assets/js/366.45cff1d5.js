(window.webpackJsonp=window.webpackJsonp||[]).push([[366],{859:function(n,t,e){"use strict";e.r(t);var a=e(6),i=Object(a.a)({},(function(){var n=this,t=n.$createElement,e=n._self._c||t;return e("ContentSlotsDistributor",{attrs:{"slot-key":n.$parent.slotKey}},[e("h2",{attrs:{id:"spring-cloud整合zipkin进行服务跟踪"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#spring-cloud整合zipkin进行服务跟踪"}},[n._v("#")]),n._v(" Spring Cloud整合Zipkin进行服务跟踪")]),n._v(" "),e("div",{staticClass:"language- extra-class"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[n._v('Zipkin 是 Twitter 的一个开源项目，是一个致力于收集所有服务的监控数据的分布式跟踪系统，它提供了收集数据和查询数据两大接口服务。有了 Zipkin 我们就可以很直观地对调用链进行查看，并且可以很方便地看出服务之间的调用关系以及调用耗费的时间。\nZipkin 数据收集服务\n部署 Zipkin 需要先下载已经编译好了的 jar 包，然后 java–jar 启动即可。\ncurl -sSL https://zipkin.io/quickstart.sh | bash -s\njava -jar zipkin.jar\n\n启动后访问 http://localhost:9411/zipkin/ 就可以看到管理页面了，如图 1 所示。\n\n项目集成 Zipkin 发送调用链数据\n在前面的教程中，我们只是集成了 Spring Cloud Sleuth，然后将跟踪信息输出到日志中。现在，Zipkin 的服务部署好了，需要将链路跟踪的信息发送给 Zipkin 的收集服务。\n\n需要在项目中添加依赖，具体代码如下所示。\n<dependency>\n    <groupId>org.springframework.cloud</groupId>\n    <artifactId>spring-cloud-starter-zipkin</artifactId>\n</dependency>\n\n在属性文件中可以配置 Zipkin 的地址，默认是 http://127.0.0.1:9411，这样才能将跟踪的数据发送到执行的收集服务中。\n# 配置 zipKin Server 的地址\nspring.zipkin.base-url=http://127.0.0.1:9411\n\n然后我们启动之前的服务、访问接口，就可以看到数据已经能够在 Zipkin 的 Web 页面中了，如图 2 和图 3 所示。\n\nZipkin链路列表\n图 2  Zipkin 链路列表\n\nZipkin链路详情\n图 3  Zipkin 链路详情\n\n停掉被访问的服务，模拟一下异常情况，通过 Zipkin 的 UI 可以快速发现请求异常的信息，如图 4 所示。\n\nZipkin异常请求\n图 4  Zipkin 异常请求\n\n还可以查询异常的详细信息，如图 5 所示。\n\nZipkin链路异常信息详情\n图 5  Zipkin 链路异常信息详情\n抽样采集数据\n在实际使用中可能调用了 10 次接口，但是 Zipkin 中只有一条数据，这是因为收集信息是有一定比例的，这并不是 bug。Zipkin 中的数据条数与调用接口次数默认比例是 0.1，当然我们也可以通过配置来修改这个比例值：\n#zipkin 抽样比例\nspring.sleuth.sampler.probability=1.0\n\n之所以有这样的一个配置，是因为在高并发下，如果所有数据都采集，那这个数据量就太大了，采用抽样的做法可以减少一部分数据量，特别是对于 Http 方式去发送采集数据，对性能有很大的影响。\n异步任务线程池定义\nSleuth 对异步任务也是支持的，我们用 @Async 开启一个异步任务后，Sleuth 会为这个调用新创建一个 Span。\n\n如果你自定义了异步任务的线程池，会导致无法新创建一个 Span，这就需要使用 Sleuth 提供的 LazyTraceExecutor 来包装下。代码如下所示。\n@Configuration\n@EnableAutoConfiguration\npublic class CustomExecutorConfig extends AsyncConfigurerSupport {\n    @Autowired\n    BeanFactory beanFactory;\n    @Override\n    public Executor getAsyncExecutor() {\n        ThreadPoolTaskExecutor executor = new ThreadPoolTaskExecutor();\n        executor.setCorePoolSize(7);\n        executor.setMaxPoolSize(42);\n        executor.setQueueCapacity(11);\n        executor.setThreadNamePrefix("zhangsan-");\n        executor.initialize();\n        return new LazyTraceExecutor(this.beanFactory, executor);\n    }\n}\n如果直接 return executor 就不会新建 Span，也就不会有 save-log 这个 Span。如图 6 所示。\n\nZipkin Span信息\n图 6  Zipkin Span 信息\nTracingFilter\nTracingFilter 是负责处理请求和响应的组件，我们可以通过注册自定义的 TracingFilter 实例来实现一些扩展性的需求。下面给大家演示下如何给请求添加自定义的标记以及将请求 ID 添加到响应头返回给客户端。代码如下所示。\n@Component\n@Order(TraceWebServletAutoConfiguration.TRACING_FILTER_ORDER + 1)\nclass MyFilter extends GenericFilterBean {\n    private final Tracer tracer;\n    MyFilter(Tracer tracer) {\n        this.tracer = tracer;\n    }\n    @Override\n    public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain)\n            throws IOException, ServletException {\n        Span currentSpan = this.tracer.currentSpan();\n        if (currentSpan == null) {\n            chain.doFilter(request, response);\n            return;\n        }\n        ((HttpServletResponse) response).addHeader("ZIPKIN-TRACE-ID", currentSpan.context().traceIdString());\n        currentSpan.tag("custom", "tag");\n        chain.doFilter(request, response);\n    }\n}\n我们在响应头中设置了请求 ID，可以通过查看请求的响应信息来验证是否设置成功，如图 7 所示。\n\n查询请求响应信息\n图 7  查询请求响应信息\n\n手动创建的标记可以在 Zipkin 中查看，如图 8 所示。\n\nZipkin自定义标记信息\n图 8  Zipkin 自定义标记信息\n\n自定义标记是一个非常实用的功能，可以将请求对应的用户信息标记上去，排查问题时非常有帮助。\n监控本地方法\n异步执行和远程调用都会新开启一个 Span，如果我们想监控本地的方法耗时时间，可以采用埋点的方式监控本地方法，也就是开启一个新的 Span。代码如下所示。\n@Autowired\nTracer tracer;\n@Override\npublic void saveLog2(String log) {\n    ScopedSpan span = tracer.startScopedSpan("saveLog2");\n    try {\n        Thread.sleep(2000);\n    } catch (Exception | Error e) {\n        span.error(e);\n    } finally {\n        span.finish();\n    }\n}\n通过手动埋点的方式可以创建新的 Span，在 Zipkin 的 UI 中也可以看到这个本地方法执行所消耗的时间，可以看到 savelog2 花费了 2 秒的时间，如图 9 所示。\n\nZipkin手动埋点数据信息\n图 9  Zipkin 手动埋点数据信息\n\n除了使用代码手动创建 Span，还有一种更简单的方式，那就是在方法上加上下面的注解：\n@NewSpan(name = "saveLog2")\n\n过滤不想跟踪的请求\n对于某些请求不想开启跟踪，可以通过配置 HttpSampler 来过滤掉，比如 swagger 这些请求等。代码如下所示。\n@Bean(name = ServerSampler.NAME)\nHttpSampler myHttpSampler(SkipPatternProvider provider) {\n    Pattern pattern = provider.skipPattern();\n    return new HttpSampler() {\n        @Override\n        public <Req> Boolean trySample(HttpAdapter<Req, ?> adapter, Req request) {\n            String url = adapter.path(request);\n            boolean shouldSkip = pattern.matcher(url).matches();\n            if (shouldSkip) {\n                return false;\n            }\n            return null;\n        }\n    };\n}\n核心在 trySample 方法中，只要不想跟踪的 URL 直接返回 false 就可以过滤。规则可以自定，笔者用了 SkipPatternProvider 来过滤，SkipPatternProvider 中的 skipPattern 配置了很多过滤规则。\n/api-docs.*|/autoconfig|/configprops|/dump|/health|/info|/metrics.*|\n/mappings|/trace|/swagger.*|.*\\.png|.*\\.css|.*\\.js|.*\\.html|/favicon.ico|\n/hystrix.stream|/application/.*|/actuator.*|/cloudfoundryapplication\n\n用RabbitMq代替Http发送调用链数据\n虽然有基于采样的收集方式，但是数据的发送采用 Http 还是对性能有影响。如果 Zipkin 的服务端重启或者挂掉了，那么将丢失部分采集数据。为了解决这些问题，我们将集成 RabbitMq 来发送采集数据，利用消息队列来提高发送性能，保证数据不丢失。\n\n在服务中增加 RabbitMq 的依赖：\n<dependency>\n    <groupId>org.springframework.amqp</groupId>\n    <artifactId>spring-rabbit</artifactId>\n</dependency>\n\n然后在属性文件中增加 RabbitMq 的连接配置：\n# 修改zipkin的数据发送方式为RabbitMq\nspring.zipkin.sender.type=RABBIT\n# rabbitmq 配置\nspring.rabbitmq.addresses=amqp://192.168.10.124:5672\nspring.rabbitmq.username=zhangsan\nspring.rabbitmq.password=123456\n\n到这里，集成就已经完成了，记得去掉之前配置的 spring.zipkin.base-url。因为我们现在利用 RabbitMq 来发送数据了，所以这个配置就不需要了。\n\n数据发送方已经采用 RabbitMq 来发送调用链数据，但是 Zipkin 服务并不知道 RabbitMq 的信息，所以我们在启动 Zipkin 服务的时候需要指定 RabbitMq 的信息。\njava -DRABBIT_ADDRESSES=192.168.10.124:5672 - DRABBIT_USER=zhangsan -DRABBIT_PASSWORD=123456 -jar zipkin.jar\n\n用Elasticsearch存储调用链数据\n目前我们收集的数据都是存在 Zipkin 服务的内存中，服务一重启这些数据就没了，我们需要将这些数据持久化。我们可以将其存储在 MySQL 中，实际使用中数据量可能会比较大，所以 MySQL 并不是一种很好的选择，可以选择用 Elasticsearch 来存储数据，Elasticsearch 在搜索方面有先天的优势。\n\n启动 Zipkin 的时候指定存储类型为 ES，指定 ES 的 URL 信息：\njava -DSTORAGE_TYPE=elasticsearch -DES_HOSTS=http://localhost:9200 - DRABBIT_ADDRESSES=192.168.10.124:5672 -DRABBIT_USER=zhangsan -DRABBIT_PASSWORD=123456 -jar zipkin.jar\n\n重启服务，然后收集一些数据，我们可以通过两种方式来验证数据是否存储到了 Elasticsearch 中。\n\n可以重启 Zipkin 服务，然后看看数据是否还存在，如果存在则证明数据已经是持久化了。\n\n可以通过查看 Elasticsearch 中的数据来确认数据有没有存储成功，访问 Elasticsearch 的地址查看当前所有的索引信息：http://localhost：9200/_cat/indices。\nyellow open zipkin:span-2019-01-22 P0QTytShTWmAyZVg61dmRg 5 1 5 0 33.6kb 33.6kb\n\n可以看到当前节点下面有哪些索引，如果看到有以 zipkin 开头的就说明索引创建了，接着直接查询这个索引下是否有数据即可认证是否存储成功，访问 http://localhost：9200/索引名称/_search。\n\n')])])]),e("p",[e("img",{attrs:{src:"http://c.biancheng.net/uploads/allimg/190829/5-1ZRZ9313XF.png",alt:"RUNOOB 图标"}})]),n._v(" "),e("p",[e("img",{attrs:{src:"http://c.biancheng.net/uploads/allimg/190829/5-1ZRZ934403R.png",alt:"RUNOOB 图标"}})]),n._v(" "),e("p",[e("img",{attrs:{src:"http://c.biancheng.net/uploads/allimg/190829/5-1ZRZ93U4195.png",alt:"RUNOOB 图标"}})]),n._v(" "),e("p",[e("img",{attrs:{src:"http://c.biancheng.net/uploads/allimg/190829/5-1ZRZ9420R02.png",alt:"RUNOOB 图标"}})]),n._v(" "),e("p",[e("img",{attrs:{src:"http://c.biancheng.net/uploads/allimg/190829/5-1ZRZ944461A.gif",alt:"RUNOOB 图标"}})]),n._v(" "),e("p",[e("img",{attrs:{src:"http://c.biancheng.net/uploads/allimg/190830/5-1ZS009134Ac.png",alt:"RUNOOB 图标"}})]),n._v(" "),e("p",[e("img",{attrs:{src:"http://c.biancheng.net/uploads/allimg/190830/5-1ZS0091I61O.png",alt:"RUNOOB 图标"}})]),n._v(" "),e("p",[e("img",{attrs:{src:"http://c.biancheng.net/uploads/allimg/190830/5-1ZS0092153T5.gif",alt:"RUNOOB 图标"}})]),n._v(" "),e("p",[e("img",{attrs:{src:"http://c.biancheng.net/uploads/allimg/190830/5-1ZS0092I4336.png",alt:"RUNOOB 图标"}})])])}),[],!1,null,null,null);t.default=i.exports}}]);