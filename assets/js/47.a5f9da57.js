(window.webpackJsonp=window.webpackJsonp||[]).push([[47],{535:function(t,a,s){"use strict";s.r(a);var n=s(6),r=Object(n.a)({},(function(){var t=this,a=t.$createElement,s=t._self._c||a;return s("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[s("h2",{attrs:{id:"spark-streaming-编程模型"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#spark-streaming-编程模型"}},[t._v("#")]),t._v(" Spark(Streaming)编程模型")]),t._v(" "),s("p",[t._v("DStream 的操作流程\nDStream 作为 Spark Streaming 的基础抽象，它代表持续性的数据流。这些数据流既可以通过外部输入源来获取，也可以通过现有的 DStream 的 Transformation 操作来获得。")]),t._v(" "),s("p",[t._v("在内部实现上，DStream 由一组时间序列上连续的 RDD 来表示。如图 1 所示，每个 RDD 都包含了自己特定时间间隔内的数据流。\n"),s("img",{attrs:{src:"http://c.biancheng.net/uploads/allimg/190516/5-1Z516103022358.gif",alt:"RUNOOB 图标"}}),t._v("\n如图 2 所示，对 DStream 中数据的各种操作也是映射到内部的 RDD 上来进行的，可以通过 RDD 的 Transformation 生成新的 DStream。这里的执行引擎是 Spark。\n"),s("img",{attrs:{src:"http://c.biancheng.net/uploads/allimg/190516/5-1Z516103414515.gif",alt:"RUNOOB 图标"}}),t._v("\nSpark Streaming 使用\n作为构建于 Spark 之上的应用框架，Spark Streaming 承袭了 Spark 的编程风格。本节以 Spark Streaming 官方提供的 WordCount 代码为例来介绍 Spark Streaming 的使用方式。")]),t._v(" "),s("div",{staticClass:"language-java extra-class"},[s("pre",{pre:!0,attrs:{class:"language-java"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),t._v("_\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("streaming"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),t._v("_\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("streaming"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("StreamingContext")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//创建一个拥有两个工作线程，时间片长度为 1 秒的 StreamContext")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//主结点需要 2 核以免饥饿状态发生")]),t._v("\nval conf "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("SparkConf")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("setMaster")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"local[2]"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("setAppName")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"NetworkWordCount"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\nval ssc "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("StreamingContext")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("conf"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Seconds")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 创建连接至 hostname:port 的 DStreamCreate,如 localhost:9999")]),t._v("\nval lines "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ssc"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("socketTextStream")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"localhost"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("9999")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//把每一行分解为单词")]),t._v("\nval words "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" lines"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("flatMap "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("split")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('""')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spark"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("streaming"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("StreamingContext")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//计数每一个时间片内的单词量")]),t._v("\nval pairs "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" words"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("map")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("word "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("word"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nval wordCounts "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("  pairs"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("reduceByKey")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("_"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//打印该 DStream 生成的每个 RDD 中的前 10 个单词")]),t._v("\nwordCounts"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nssc"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("start")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 启动计算")]),t._v("\nssc"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("awaitTermination")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//等待计算完成")]),t._v("\n")])])]),s("ol",[s("li",[t._v("创建 StreamingContext 对象\nSpark Streaming 初始化的主要工作是创建 Streaming Context 对象，通过创建函数的参数指明 Master Server，设定应用名称，指定 Spark Streaming 处理数据的时间间隔等。上述代码可设定应用的名称为 NetworkWordCount，处理数据的时间间隔为 1 秒。")]),t._v(" "),s("li",[t._v("创建 InputDStream\nSpark Streaming 需要指明数据源。该实例指明使用 socketTextStream，也就是以 socket 连接作为数据源读取数据。Spark Streaming 支持多种不同的数据源，包括 Kafka、Flume、HDFS/S3、Kinesis、Twitter。")]),t._v(" "),s("li",[t._v("操作 DStream\n对于从数据源得到的 DStream，用户可以对其进行各种操作，该实例所示的操作就是一个典型的 WordCount 执行流程。对于当前时间窗口内从数据源得到的数据，首先进行分割，然后利用 map 和 reduceByKey 方法进行计算，最后使用 print() 方法输出结果。")]),t._v(" "),s("li",[t._v("启动 Spark Streaming\n之前的所有步骤只是创建了执行流程，程序没有真正连接上数据源，也没有对数据进行任何操作，只是设定好了所有的执行计划，当 ssc.start() 启动后程序才真正进行所有预期的操作。\nDStream 的输入源\nSpark Streaming 的所有操作都是基于流的，而输入源是这一系列操作的起点。输入 DStream 和 DStream 接收的流都代表输入数据流的来源，Spark Streaming 提供了两种内置数据流来源：基础来源和高级来源。")]),t._v(" "),s("li",[t._v("基础来源\n基础来源是在 StreamingContext API 中直接可用的来源，如文件系统、Socket （套接字）等。")])]),t._v(" "),s("p",[t._v("前面的例子已经使用了 ssc.socketTextStream() 方法，即通过 TCP 套接字连接，从文本数据中创建一个 DStream。除了套接字之外，StreamingContext 的 API 还提供了从文件和 Akka actors 中创建 DStreams 作为输入源的方法。")]),t._v(" "),s("p",[t._v("Spark Streaming 提供了streamingContext.fileStream(dataDirectory) 方法，该方法可以从任何文件系统（如 HDFS、S3、NFS 等）的文件中读取数据，然后创建一个 DStream。")]),t._v(" "),s("p",[t._v("Spark Streaming 监控 dataDirectory 目录和在该目录下的所有文件的创建处理过程。需要注意的是，文件必须是具有相同的数据格式的，创建的文件必须在 dataDirectory 目录下。对于简单的文本文件，可以使用一个简单的方法 StreamingContext.textFileStream(dataDirectory) 来读取数据。")]),t._v(" "),s("p",[t._v("Spark Streaming 也可以基于自定义 Actors 的流创建 DStream。通过 Akka actors 接收数据流的使用方法是 streamingContext.actorStream(actorProps,actor—name)。")]),t._v(" "),s("p",[t._v("Spark Streaming 使用 streamingContext.queueStream（queueOfRDDs）方法可以创建基于 RDD 队列的 DStream，每个 RDD 队列将被视为 DStream 中的一块数据流进行加工处理。\n2.高级来源\n局级来源，如 Kafka、Flume、Kinesis、Twitter 等，可以通过额外的实用工具类来创建。高级来源需要外部 non-Spark 库的接口，其中一些有复杂的依赖关系（如 Kafka、Flume)。因此通过这些来源创建 DStreams 需要明确其依赖。例如，如果想创建一个使用 Twitter tweets 的数据的 DStream 流，必须按以下步骤来做。")]),t._v(" "),s("p",[t._v("1）在 sbt 或 maven 工程里添加 spark-streaming-twitter_2.10 依赖。")]),t._v(" "),s("p",[t._v("2）开发：导入 TwitterUtils 包，通过 TwitterUtils.createStream 方法创建一个 DStream。")]),t._v(" "),s("p",[t._v("3）部署：添加所有依赖的 Jar 包，然后部署应用程序。")]),t._v(" "),s("p",[t._v("需要注意的是，这些高级来源一般在 Spark Shell 中不可用，因此基于这些高级来源的应用不能在 Spark Shell 中进行测试。如果必须在 Spark Shell 中使用它们，则需要下载相应的 maven 工程的 Jar 依赖并添加到类路径中。另外，输入 DStream 也可以创建自定义的数据源，需要做的就是实现一个用户定义的接收器。")])])}),[],!1,null,null,null);a.default=r.exports}}]);