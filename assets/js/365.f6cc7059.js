(window.webpackJsonp=window.webpackJsonp||[]).push([[365],{854:function(n,e,t){"use strict";t.r(e);var s=t(6),a=Object(s.a)({},(function(){var n=this.$createElement,e=this._self._c||n;return e("ContentSlotsDistributor",{attrs:{"slot-key":this.$parent.slotKey}},[e("h2",{attrs:{id:"spring-cloud-sleuth与elk-日志分析系统-配合使用"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#spring-cloud-sleuth与elk-日志分析系统-配合使用"}},[this._v("#")]),this._v(" Spring Cloud Sleuth与ELK（日志分析系统）配合使用")]),this._v(" "),e("div",{staticClass:"language- extra-class"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[this._v('在《Spring Cloud使用Sleuth在应用中进行日志跟踪》教程中的案例，我们已经实现了服务调用之间的链路追踪，但是这些日志是分散在各个机器上的，就算出现问题了，我们想快速定位，也得从各个机器把日志整合起来，再去查问题。\n\n这个时候就需要引入日志分析系统了，比如 ELK，可以将多台服务器上的日志信息统一收集起来，在出问题的时候我们可以轻松根据 traceId 来搜索出对应的请求链路信息。\nELK 简介\nELK 由三个组件组成：\nElasticsearch 是个开源分布式搜索引擎，它的特点有分布式、零配置、自动发现、索引自动分片、索引副本机制、restful 风格接口、多数据源、自动搜索负载等。\nLogstash 是一个完全开源的工具，它可以对日志进行收集、分析并存储以供以后使用。\nkibana 是一个开源和免费的工具，它可以为 Logstash 和 ElasticSearch 提供日志分析友好的 Web 界面，可以汇总、分析和搜索重要数据日志。\n输出 JSON 格式日志\n可以通过 logback 来输出 Json 格式的日志，让 Logstash 收集存储到 Elasticsearch 中，然后在 kibana 中查看。想要输入 Json 格式的数据需要加一个依赖，具体代码如下所示。\n\x3c!-- 输出 Json 格式日志 --\x3e\n<dependency>\n    <groupId>net.logstash.logback</groupId>\n    <artifactId>logstash-logback-encoder</artifactId>\n    <version>5.2</version>\n</dependency>\n\n然后创建一个 logback-spring.xml 文件。配置 logstash 需要收集的数据格式如下：\n\x3c!-- Appender to log to file in a JSON format --\x3e\n<appender name="logstash"\n    class="ch.qos.logback.core.rolling.RollingFileAppender">\n    <file>${LOG_FILE}.json</file>\n    <rollingPolicy\n        class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">\n        <fileNamePattern>${LOG_FILE}.json.%d{yyyy-MM-dd}.gz</fileNamePattern>\n        <maxHistory>7</maxHistory>\n    </rollingPolicy>\n    <encoder\n        class="net.logstash.logback.encoder.LoggingEventCompositeJsonEncoder">\n        <providers>\n            <timestamp>\n                <timeZone>UTC</timeZone>\n            </timestamp>\n            <pattern>\n                <pattern>\n                    {\n                    "severity": "%level",\n                    "service": "${springAppName:-}",\n                    "trace": "%X{X-B3-TraceId:-}",\n                    "span": "%X{X-B3-SpanId:-}",\n                    "parent": "%X{X-B3-ParentSpanId:-}",\n                    "exportable":\n                    "%X{X-Span-Export:-}",\n                    "pid": "${PID:-}",\n                    "thread": "%thread",\n                    "class": "%logger{40}",\n                    "rest": "%message"\n                    }\n                </pattern>\n            </pattern>\n        </providers>\n    </encoder>\n</appender>\n集成好后就能在输出的日志目录中看到有一个以“.json”结尾的日志文件了，里面的数据格式是 Json 形式的，可以直接通过 Logstash 进行收集。\n{\n    "@timestamp": "2019-11-30T01:48:32.221+00:00",\n    "severity": "DEBUG",\n    "service": "fsh-substitution",\n    "trace": "41b5a575c26eeea1",\n    "span": "41b5a575c26eeea1",\n    "parent": "41b5a575c26eeea1",\n    "exportable": "false",\n    "pid": "12024",\n    "thread": "hystrix-fsh-house-10",\n    "class": "c.f.a.client.fsh.house.HouseRemoteClient",\n    "rest": "[HouseRemoteClient#hosueInfo] <--- END HTTP (796-byte body)"\n}\n\n日志收集存入 ElasticSearch 之后，就可以用 Kibana 进行展示。需要排查某个请求的问题时，直接根据 traceid 搜索，就可以把整个请求链路相关的日志信息查询出来。\n\n')])])])])}),[],!1,null,null,null);e.default=a.exports}}]);